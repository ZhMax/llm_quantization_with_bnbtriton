# llm_quantization_with_bnbtriton
Using bnbtriton kernels for W8A8 quantization of LLMs
